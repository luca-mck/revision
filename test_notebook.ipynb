{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "image_folder = \"./data/images\"\n",
    "annotation_folder = \"./data/annotations\"\n",
    "image_type = \".jpg\"\n",
    "annotation_type = \".xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images and annotations \n",
    "# logic: different folders/same file name/different file type\n",
    "def get_files(image_folder, annotation_folder, image_type=\".jpg\", annotation_type=\".xml\"):\n",
    "    files = [\n",
    "    (os.path.join(image_folder, image_file), os.path.join(annotation_folder, image_file.replace(image_type, annotation_type))) \\\n",
    "        for image_file in os.listdir(image_folder)\n",
    "    ]\n",
    "    return files\n",
    "\n",
    "# parse xml file\n",
    "def get_annotation(file_path):\n",
    "    tree = ET.parse(file_path) \n",
    "    root = tree.getroot()\n",
    "    bbox_coordinates = []\n",
    "    class_name = []\n",
    "    for member in root.findall('object'):\n",
    "        class_name.append(member[0].text) # class name\n",
    "            \n",
    "        # bbox coordinates\n",
    "        xmin = int(member[4][0].text)\n",
    "        ymin = int(member[4][1].text)\n",
    "        xmax = int(member[4][2].text)\n",
    "        ymax = int(member[4][3].text)\n",
    "        # store data in list\n",
    "        bbox_coordinates.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return {\"class_name\": class_name,\n",
    "    \"bbox\": torch.Tensor(bbox_coordinates)}\n",
    "\n",
    "# visualize annotation\n",
    "def get_visualization(image_tensor, annotations, out_path = None):\n",
    "    transformer = ToPILImage()\n",
    "    annotated_tensor = draw_bounding_boxes(image_tensor, annotations)\n",
    "    annotated_image = transformer(annotated_tensor)\n",
    "    if out_path is None:\n",
    "        annotated_image.show()\n",
    "    else:\n",
    "        annotated_image.save(out_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data module\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ObjectDetectionDataSet(Dataset):\n",
    "    def __init__(self, data_tuples, tranformations = None) -> None:\n",
    "        super().__init__()\n",
    "        self.data_tuples = data_tuples\n",
    "        self.transformations = tranformations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_tuples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = read_image(self.data_tuples[index][0])\n",
    "        annotations = get_annotation(self.data_tuples[index][1])\n",
    "        if self.transformations:\n",
    "            img = self.transformations(img)\n",
    "        return img, annotations\n",
    "\n",
    "class ObjectDetectionDataModule(LightningDataModule):\n",
    "    def __init__(self, image_folder, annotation_folder, transformations=None, test_suffix=None):\n",
    "        super().__init__()\n",
    "        self.image_folder = image_folder\n",
    "        self.annotation_folder = annotation_folder\n",
    "        self.transform = transformations\n",
    "        self.train_val_split = 0.8\n",
    "        self.test_suffix = test_suffix\n",
    "        if test_suffix:\n",
    "            self.image_folder_test = image_folder + test_suffix\n",
    "            self.annotation_folder_test = annotation_folder + test_suffix\n",
    "\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        self.data_tuples = get_files(self.image_folder, self.annotation_folder)\n",
    "        train_len = int(len(self.data_tuples)*self.train_val_split)\n",
    "        val_len = len(self.data_tuples) - train_len\n",
    "        self.seq_lengths = [train_len, val_len]\n",
    "        if self.test_suffix:\n",
    "            self.data_tuples_test = get_files(self.image_folder_test, self.annotation_folder_test)\n",
    "        else:\n",
    "            self.data_tuples_test = []\n",
    "\n",
    "    def setup(self, stage: str = \"fit\"):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            dataset = ObjectDetectionDataSet(self.data_tuples, self.transform)\n",
    "            \n",
    "            self.train_set, self.val_set = random_split(dataset, self.seq_lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.test_set = ObjectDetectionDataSet(self.data_tuples_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_det = ObjectDetectionDataModule(\n",
    "    image_folder,\n",
    "    annotation_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profiler import SimpleProfiler\n",
    "from .config import config_file\n",
    "\n",
    "ObjectDetectionLogger = TensorBoardLogger())\n",
    "ObjectDetectionCheckoints = []\n",
    "ObjectDetectionProfiler = SimpleProfiler()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23d104a41f313c149af75e41d34ce1fe6f8f93e6801966a392600b2206065955"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('forecasting_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
